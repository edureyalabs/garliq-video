# video_modal_final.py
import modal
import os
import time
import base64

app = modal.App("garliq-video-backend")

base_image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(
        "crewai==0.86.0",
        "crewai-tools==0.17.0",
        "litellm==1.79.1",
        "anthropic>=0.18.0",
        "requests==2.31.0",
        "supabase==2.7.4",
        "httpx==0.27.0",
        "pydantic>=2.6.1",
        "fastapi==0.104.1",
        "uvicorn==0.24.0"
    )
    .apt_install("ffmpeg")
    .add_local_dir(".", "/root")
)

render_image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install("playwright==1.40.0")
    .apt_install("ffmpeg")
    .run_commands("playwright install chromium", "playwright install-deps")
    .add_local_dir(".", "/root")
)

secrets = modal.Secret.from_name("garliq-secrets")


@app.function(
    image=render_image,
    timeout=600,
    cpu=2.0,
    memory=4096,
    secrets=[secrets],
    retries=0
)
def render_segment_video(segment: dict, audio_base64: str, audio_duration: float, animation_html: str) -> str:
    """
    Render segment video using AI-generated HTML5 animation code
    
    Args:
        segment: dict with index, text, visual_hint
        audio_base64: base64-encoded audio WAV data
        audio_duration: duration of audio in seconds
        animation_html: AI-generated complete HTML animation code
        
    Returns:
        Base64-encoded MP4 file data (5 Mbps bitrate, normalized for concatenation)
    """
    from playwright.sync_api import sync_playwright
    import subprocess
    
    # Import config for timeout
    import sys
    sys.path.insert(0, '/root')
    from video_config import FFMPEG_TIMEOUT_SECONDS
    
    segment_index = segment['index']
    segment_text = segment['text']
    
    print(f"üé® [{segment_index}] Starting: {segment_text[:40]}...")
    print(f"    Audio duration: {audio_duration:.1f}s")
    print(f"    Animation HTML: {len(animation_html)} chars")
    print(f"    Target bitrate: 5 Mbps (normalized encoding)")
    
    # STEP 1: Decode audio from base64
    try:
        audio_bytes = base64.b64decode(audio_base64)
        if len(audio_bytes) < 1000:
            raise Exception(f"Audio too small: {len(audio_bytes)} bytes")
    except Exception as e:
        raise Exception(f"Audio decode failed: {e}")
    
    # Save audio to temp file
    audio_path = f'/tmp/audio_{segment_index}.wav'
    with open(audio_path, 'wb') as f:
        f.write(audio_bytes)
    
    print(f"‚úì [{segment_index}] Audio decoded: {len(audio_bytes)} bytes")
    
    # STEP 2: Calculate video duration (minimum 12 seconds)
    video_duration_ms = max(int(audio_duration * 1000) + 1000, 12000)
    
    # STEP 3: Prepare HTML with recording infrastructure
    html_content = animation_html
    
    # Check if HTML has required recording interface
    if 'window.startRecording' not in html_content:
        print(f"‚ö†Ô∏è  [{segment_index}] Adding recording interface to HTML")
        
        # Inject recording interface before </script> or before </body>
        recording_code = f"""
        
        // ========== RECORDING INTERFACE (AUTO-INJECTED) ==========
        window.startRecording = function() {{
            return new Promise((resolve) => {{
                console.log('Recording started');
                setTimeout(() => {{
                    window.recordingComplete = true;
                    console.log('Recording complete');
                    resolve();
                }}, {video_duration_ms});
            }});
        }};
        """
        
        if '</script>' in html_content:
            html_content = html_content.replace('</script>', recording_code + '\n</script>', 1)
        elif '</body>' in html_content:
            html_content = html_content.replace('</body>', f'<script>{recording_code}</script>\n</body>', 1)
        else:
            html_content += f'<script>{recording_code}</script>'
    
    # Save HTML to file
    html_path = f'/tmp/segment_{segment_index}.html'
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"‚úì [{segment_index}] HTML prepared")
    
    # STEP 4: Render with Playwright
    webm_path = f'/tmp/segment_{segment_index}.webm'
    
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(
                headless=True,
                args=[
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-web-security',
                    '--disable-features=IsolateOrigins,site-per-process'
                ]
            )
            
            context = browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                device_scale_factor=1
            )
            
            page = context.new_page()
            
            # Console logging
            page.on('console', lambda msg: print(f"  Browser [{msg.type}]: {msg.text}"))
            page.on('pageerror', lambda err: print(f"  Browser Error: {err}"))
            
            # Navigate to HTML
            page.goto(f'file://{html_path}')
            
            # Wait for page to be ready
            page.wait_for_timeout(2000)
            
            # Check if animation is ready
            try:
                page.wait_for_function(
                    "window.startRecording !== undefined || document.readyState === 'complete'",
                    timeout=5000
                )
            except:
                print(f"‚ö†Ô∏è  [{segment_index}] Animation ready check timeout, proceeding anyway")
            
            # Start recording
            print(f"  üìπ Starting recording ({video_duration_ms}ms)...")
            
            # Method 1: Use built-in canvas recording if available
            if '<canvas' in html_content.lower():
                recording_script = f"""
                    const canvas = document.getElementById('canvas') || document.querySelector('canvas');
                    if (!canvas) {{
                        throw new Error('No canvas element found');
                    }}
                    
                    const stream = canvas.captureStream(30); // 30 FPS
                    const mediaRecorder = new MediaRecorder(stream, {{
                        mimeType: 'video/webm;codecs=vp9',
                        videoBitsPerSecond: 5000000
                    }});
                    
                    const chunks = [];
                    mediaRecorder.ondataavailable = e => {{
                        if (e.data.size > 0) chunks.push(e.data);
                    }};
                    
                    mediaRecorder.onstop = () => {{
                        const blob = new Blob(chunks, {{ type: 'video/webm' }});
                        const reader = new FileReader();
                        reader.onloadend = () => {{
                            window.recordedVideoData = reader.result.split(',')[1];
                            window.recordingComplete = true;
                        }};
                        reader.readAsDataURL(blob);
                    }};
                    
                    mediaRecorder.start(100);
                    
                    setTimeout(() => {{
                        mediaRecorder.stop();
                    }}, {video_duration_ms});
                """
                
                page.evaluate(recording_script)
            else:
                # Method 2: CSS/SVG animations - call provided startRecording
                page.evaluate('if (window.startRecording) window.startRecording()')
            
            # Wait for recording to complete
            page.wait_for_function(
                'window.recordingComplete === true',
                timeout=int(video_duration_ms) + 10000
            )
            
            # Get recorded video data
            video_data_base64 = page.evaluate('window.recordedVideoData')
            
            if not video_data_base64:
                raise Exception("No video data captured")
            
            # Save WebM
            with open(webm_path, 'wb') as f:
                f.write(base64.b64decode(video_data_base64))
            
            page.close()
            context.close()
            browser.close()
        
        print(f"‚úì [{segment_index}] WebM captured: {os.path.getsize(webm_path)} bytes")
        
    except Exception as e:
        print(f"‚ùå [{segment_index}] Playwright rendering failed: {e}")
        
        # Fallback: Create a simple video with text
        print(f"  üîÑ Creating fallback video...")
        fallback_mp4 = f'/tmp/segment_{segment_index}_fallback.mp4'
        
        try:
            # Create simple video with text overlay
            subprocess.run([
                'ffmpeg', '-y',
                '-f', 'lavfi',
                '-i', f"color=c=black:s=1920x1080:d={audio_duration}",
                '-vf', f"drawtext=text='Segment {segment_index}':fontsize=60:fontcolor=white:x=(w-text_w)/2:y=(h-text_h)/2",
                '-c:v', 'libx264',
                '-preset', 'ultrafast',
                '-pix_fmt', 'yuv420p',
                fallback_mp4
            ], capture_output=True, timeout=30)
            
            webm_path = fallback_mp4
            print(f"‚úì [{segment_index}] Fallback video created")
        except:
            raise Exception("Both rendering and fallback failed")
    
    # STEP 5: Verify WebM/Video file
    if not os.path.exists(webm_path) or os.path.getsize(webm_path) < 10000:
        raise Exception(f"Video file invalid: {webm_path}")
    
    # STEP 6: Merge with audio + NORMALIZE ENCODING for guaranteed concatenation compatibility
    mp4_path = f'/tmp/segment_{segment_index}_final.mp4'
    
    try:
        result = subprocess.run([
            'ffmpeg', '-y',
            '-i', webm_path,
            '-i', audio_path,
            
            # ‚úÖ VIDEO ENCODING - NORMALIZED FOR CONCATENATION
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-profile:v', 'high',          # Consistent profile
            '-level', '4.0',               # Consistent level
            '-pix_fmt', 'yuv420p',         # Consistent pixel format
            
            # ‚úÖ FRAME RATE & TIMING - CRITICAL FOR CONCAT
            '-r', '30',                    # Fixed 30 FPS
            '-video_track_timescale', '30000',  # Fixed timescale (30000 = 30 fps * 1000)
            '-vsync', 'cfr',               # Constant frame rate (no drops)
            
            # ‚úÖ GOP & KEYFRAMES - ENSURES CLEAN BOUNDARIES
            '-g', '30',                    # Keyframe every 30 frames (1 second)
            '-keyint_min', '30',           # Minimum keyframe interval
            '-sc_threshold', '0',          # Disable scene change detection
            
            # ‚úÖ BITRATE CONTROL
            '-b:v', '5000k',
            '-maxrate', '5500k',
            '-bufsize', '10000k',
            
            # ‚úÖ STREAMING OPTIMIZATION
            '-movflags', '+faststart',
            
            # ‚úÖ AUDIO ENCODING - NORMALIZED
            '-c:a', 'aac',
            '-b:a', '128k',
            '-ar', '48000',                # Fixed 48kHz sample rate
            '-ac', '2',                    # Stereo
            
            '-shortest',
            mp4_path
        ], capture_output=True, text=True, timeout=FFMPEG_TIMEOUT_SECONDS)
        
        if result.returncode != 0:
            raise Exception(f"FFmpeg failed: {result.stderr[:200]}")
        
    except subprocess.TimeoutExpired:
        raise Exception(f"FFmpeg timeout after {FFMPEG_TIMEOUT_SECONDS}s")
    except Exception as e:
        raise Exception(f"FFmpeg error: {e}")
    
    # STEP 7: Verify MP4
    if not os.path.exists(mp4_path) or os.path.getsize(mp4_path) < 10000:
        raise Exception(f"MP4 invalid")
    
    # STEP 8: Read MP4 and encode as base64
    with open(mp4_path, 'rb') as f:
        mp4_bytes = f.read()
    
    mp4_base64 = base64.b64encode(mp4_bytes).decode('utf-8')
    
    print(f"‚úÖ [{segment_index}] Complete: {len(mp4_bytes)} bytes (5 Mbps, concat-ready)")
    
    # Cleanup
    try:
        os.remove(html_path)
        os.remove(webm_path)
        os.remove(audio_path)
        os.remove(mp4_path)
    except:
        pass
    
    return mp4_base64


@app.function(
    image=base_image,
    secrets=[secrets],
    timeout=3600,
    cpu=2.0,
    memory=4096,
)
async def process_video_generation(request_dict: dict):
    import sys
    sys.path.insert(0, '/root')
    
    from video_orchestrator_final import VideoOrchestrator
    from supabase import create_client
    
    SUPABASE_URL = os.environ["SUPABASE_URL"]
    SUPABASE_SERVICE_ROLE_KEY = os.environ["SUPABASE_SERVICE_ROLE_KEY"]
    supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)
    
    video_id = request_dict["video_id"]
    user_id = request_dict["user_id"]
    topic_category = request_dict.get("topic_category", "general")
    
    try:
        orchestrator = VideoOrchestrator(supabase=supabase, render_fn=render_segment_video)
        
        result = await orchestrator.generate_video(
            video_id=video_id,
            user_id=user_id,
            topic_category=topic_category
        )
        
        return result
        
    except Exception as e:
        print(f"‚ùå Fatal error: {e}")
        import traceback
        traceback.print_exc()
        
        try:
            supabase.table('video_generations').update({
                'generation_status': 'failed',
                'generation_error': str(e)
            }).eq('id', video_id).execute()
        except:
            pass
        
        return {"success": False, "error": str(e)}


@app.function(image=base_image, secrets=[secrets])
@modal.asgi_app()
def fastapi_app():
    from fastapi import FastAPI
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.responses import JSONResponse
    from pydantic import BaseModel
    import sys
    sys.path.insert(0, '/root')
    from video_config import MODEL_PROVIDER, MODEL_CONFIG, VIDEO_LENGTH_MINUTES, TOTAL_SEGMENTS, USE_AI_ANIMATIONS
    
    class GenerateVideoRequest(BaseModel):
        video_id: str
        user_id: str
        topic_category: str = "general"
    
    web_app = FastAPI(title="Garliq Video Backend v6.1 - Fixed Animation + Concat")
    
    web_app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    @web_app.get("/")
    def read_root():
        return {
            "status": "Garliq Video Backend v6.1 - Fixed Animation + Concat",
            "version": "6.1.0",
            "active_model_provider": MODEL_PROVIDER,
            "active_model": MODEL_CONFIG[MODEL_PROVIDER]['model'],
            "video_length_minutes": VIDEO_LENGTH_MINUTES,
            "total_segments": TOTAL_SEGMENTS,
            "ai_animations": USE_AI_ANIMATIONS,
            "architecture": "CrewAI script + AI HTML5 animations + Cloudflare Stream",
            "animation_stack": "Canvas2D + SVG + CSS3 + GSAP + Lucide",
            "fixes": [
                "‚úÖ Fixed LLM initialization for CrewAI",
                "‚úÖ Normalized video encoding for perfect concat",
                "‚úÖ Fixed timescale/framerate/GOP for stream-copy",
                "‚úÖ Added comprehensive error logging",
                "‚úÖ Guaranteed <10s concatenation time"
            ],
            "features": [
                "‚úÖ CrewAI script generation",
                "‚úÖ AI-generated HTML5 animations (full autonomy)",
                "‚úÖ Canvas2D + SVG + CSS3 animations",
                "‚úÖ GSAP + Lucide + Chart.js support",
                "‚úÖ Normalized encoding (CFR, fixed timescale)",
                "‚úÖ Ultra-fast stream-copy concatenation",
                "‚úÖ 5 Mbps bitrate streaming",
                "‚úÖ Cloudflare Stream with HLS",
                "‚úÖ Adaptive bitrate (1080p, 720p, 480p)",
                "‚úÖ Global CDN delivery"
            ]
        }
    
    @web_app.get("/health")
    def health_check():
        return {
            "status": "healthy",
            "timestamp": time.time(),
            "model_provider": MODEL_PROVIDER,
            "ai_animations": USE_AI_ANIMATIONS,
            "animation_architecture": "HTML5 (Canvas + SVG + CSS + GSAP)",
            "agent_autonomy": "FULL",
            "streaming_platform": "Cloudflare Stream",
            "concat_strategy": "normalized-encoding + stream-copy",
            "video_config": {
                "length_minutes": VIDEO_LENGTH_MINUTES,
                "total_segments": TOTAL_SEGMENTS,
                "batch_size": 10,
                "ffmpeg_timeout": 180,
                "bitrate": "5 Mbps",
                "faststart_enabled": True,
                "hls_enabled": True,
                "concat_optimized": True
            }
        }
    
    @web_app.post("/generate-video")
    async def generate_video_endpoint(request: GenerateVideoRequest):
        request_dict = {
            "video_id": request.video_id,
            "user_id": request.user_id,
            "topic_category": request.topic_category
        }
        
        process_video_generation.spawn(request_dict)
        
        return JSONResponse({
            "success": True,
            "message": "Video generation started with fixed AI animations & optimized concatenation",
            "video_id": request.video_id,
            "model_provider": MODEL_PROVIDER,
            "expected_segments": TOTAL_SEGMENTS,
            "ai_animations_enabled": USE_AI_ANIMATIONS,
            "animation_stack": "Canvas2D + SVG + CSS3 + GSAP + Lucide Icons",
            "agent_autonomy": "FULL (chooses best tools per segment)",
            "streaming_platform": "Cloudflare Stream",
            "concat_optimization": "Normalized encoding for <10s stream-copy"
        })
    
    return web_app